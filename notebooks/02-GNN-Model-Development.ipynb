{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d094967-c763-456f-bcb4-6537d13cf2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.4.1\n",
      "PyTorch Geometric version: 2.6.1\n",
      "\n",
      "Loading enriched knowledge graph from: C:\\Users\\Sheetal\\PharmacoGraph-Agent\\data\\knowledge_graph.graphml\n",
      "Graph loaded successfully.\n",
      "\n",
      "--- Verifying Graph Enrichment ---\n",
      "Number of nodes: 4388\n",
      "Number of edges: 318666\n",
      "\n",
      "Verifying attributes of drug DB00316 (Acetaminophen):\n",
      "  - type: drug\n",
      "  - mol_weight: 151.165\n",
      "  - logp: 1.3505999999999998\n",
      "  - h_bond_donors: 2\n",
      "  - h_bond_acceptors: 2\n",
      "  - tpsa: 49.33\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load Libraries and Enriched Knowledge Graph ---\n",
    "\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import ToUndirected, RandomLinkSplit\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")\n",
    "\n",
    "# --- Configuration ---\n",
    "PROJECT_ROOT = Path('.').resolve().parent\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "GRAPH_PATH = DATA_DIR / 'knowledge_graph.graphml'\n",
    "\n",
    "# --- Load the Graph ---\n",
    "print(f\"\\nLoading enriched knowledge graph from: {GRAPH_PATH}\")\n",
    "G = nx.read_graphml(GRAPH_PATH)\n",
    "print(\"Graph loaded successfully.\")\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"\\n--- Verifying Graph Enrichment ---\")\n",
    "print(f\"Number of nodes: {G.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {G.number_of_edges()}\")\n",
    "\n",
    "print(\"\\nVerifying attributes of drug DB00316 (Acetaminophen):\")\n",
    "acetaminophen_node = G.nodes['DB00316']\n",
    "for attr, value in acetaminophen_node.items():\n",
    "    print(f\"  - {attr}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa4c01d4-6e6c-4b8d-b133-ba4610760a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Preparing data for PyTorch Geometric (Corrected Bipartite Method) ---\n",
      "Node features processed and mapped separately.\n",
      "  - Drug mapping: 917 nodes, indices 0-916\n",
      "  - Reaction mapping: 3471 nodes, indices 0-3470\n",
      "\n",
      "Edge index created with type-specific indices.\n",
      "Reverse edges added.\n",
      "\n",
      "--- PyG Data Object Created Successfully ---\n",
      "HeteroData(\n",
      "  drug={ x=[917, 5] },\n",
      "  reaction={ x=[3471, 3471] },\n",
      "  (drug, causes, reaction)={ edge_index=[2, 318666] },\n",
      "  (reaction, rev_causes, drug)={ edge_index=[2, 318666] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Convert NetworkX Graph to PyG HeteroData Object (CORRECTED VERSION) ---\n",
    "import numpy as np\n",
    "\n",
    "print(\"--- Preparing data for PyTorch Geometric (Corrected Bipartite Method) ---\")\n",
    "data = HeteroData()\n",
    "\n",
    "# --- Node Processing (Separate for each type) ---\n",
    "# We need to create separate mappings for drug and reaction nodes.\n",
    "# The indices for each type MUST start from 0.\n",
    "\n",
    "# Process drug nodes\n",
    "drug_nodes = [node for node, data_dict in G.nodes(data=True) if data_dict['type'] == 'drug']\n",
    "drug_map = {node_id: i for i, node_id in enumerate(drug_nodes)}\n",
    "drug_features = []\n",
    "for drug_id in drug_nodes:\n",
    "    data_dict = G.nodes[drug_id]\n",
    "    features = [\n",
    "        float(data_dict.get('mol_weight', 0)), float(data_dict.get('logp', 0)),\n",
    "        float(data_dict.get('h_bond_donors', 0)), float(data_dict.get('h_bond_acceptors', 0)),\n",
    "        float(data_dict.get('tpsa', 0))\n",
    "    ]\n",
    "    drug_features.append(features)\n",
    "data['drug'].x = torch.tensor(drug_features, dtype=torch.float)\n",
    "\n",
    "# Process reaction nodes\n",
    "reaction_nodes = [node for node, data_dict in G.nodes(data=True) if data_dict['type'] == 'reaction']\n",
    "reaction_map = {node_id: i for i, node_id in enumerate(reaction_nodes)}\n",
    "# For reaction nodes, we use an identity matrix as features\n",
    "data['reaction'].x = torch.eye(len(reaction_nodes))\n",
    "\n",
    "print(\"Node features processed and mapped separately.\")\n",
    "print(f\"  - Drug mapping: {len(drug_map)} nodes, indices 0-{len(drug_map)-1}\")\n",
    "print(f\"  - Reaction mapping: {len(reaction_map)} nodes, indices 0-{len(reaction_map)-1}\")\n",
    "\n",
    "# --- Edge Processing (Map to new indices) ---\n",
    "# Create the edge_index using the new, type-specific mappings.\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "for u, v in G.edges():\n",
    "    # Ensure consistent ordering: source is always a drug, target is always a reaction\n",
    "    if G.nodes[u]['type'] == 'drug':\n",
    "        source_id, target_id = u, v\n",
    "    else:\n",
    "        source_id, target_id = v, u\n",
    "    \n",
    "    # Append the new, correct indices\n",
    "    source_nodes.append(drug_map[source_id])\n",
    "    target_nodes.append(reaction_map[target_id])\n",
    "\n",
    "edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "data['drug', 'causes', 'reaction'].edge_index = edge_index\n",
    "print(\"\\nEdge index created with type-specific indices.\")\n",
    "\n",
    "# --- Add reverse edges ---\n",
    "data['reaction', 'rev_causes', 'drug'].edge_index = edge_index.flip([0])\n",
    "print(\"Reverse edges added.\")\n",
    "\n",
    "print(\"\\n--- PyG Data Object Created Successfully ---\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45e451fe-879f-4c15-aa4c-e00a5257bdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Splitting links for training, validation, and testing ---\n",
      "\n",
      "--- Data Splitting Complete ---\n",
      "Training Data Sample:\n",
      "HeteroData(\n",
      "  drug={ x=[917, 5] },\n",
      "  reaction={ x=[3471, 3471] },\n",
      "  (drug, causes, reaction)={\n",
      "    edge_index=[2, 254934],\n",
      "    edge_label=[509868],\n",
      "    edge_label_index=[2, 509868],\n",
      "  },\n",
      "  (reaction, rev_causes, drug)={ edge_index=[2, 254934] }\n",
      ")\n",
      "\n",
      "Validation Data Sample:\n",
      "HeteroData(\n",
      "  drug={ x=[917, 5] },\n",
      "  reaction={ x=[3471, 3471] },\n",
      "  (drug, causes, reaction)={\n",
      "    edge_index=[2, 254934],\n",
      "    edge_label=[63732],\n",
      "    edge_label_index=[2, 63732],\n",
      "  },\n",
      "  (reaction, rev_causes, drug)={ edge_index=[2, 254934] }\n",
      ")\n",
      "\n",
      "Test Data Sample:\n",
      "HeteroData(\n",
      "  drug={ x=[917, 5] },\n",
      "  reaction={ x=[3471, 3471] },\n",
      "  (drug, causes, reaction)={\n",
      "    edge_index=[2, 286800],\n",
      "    edge_label=[63732],\n",
      "    edge_label_index=[2, 63732],\n",
      "  },\n",
      "  (reaction, rev_causes, drug)={ edge_index=[2, 286800] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Split Data into Training, Validation, and Test Sets ---\n",
    "\n",
    "print(\"--- Splitting links for training, validation, and testing ---\")\n",
    "# We will use the RandomLinkSplit transform for this.\n",
    "# It will split the 'causes' edges into three sets.\n",
    "# It also automatically adds \"negative\" edges (links that don't exist)\n",
    "# for the model to learn from, which is a crucial step.\n",
    "\n",
    "transform = RandomLinkSplit(\n",
    "    is_undirected=True,          # Our graph is undirected\n",
    "    num_val=0.1,                 # Hold out 10% of edges for validation\n",
    "    num_test=0.1,                # Hold out 10% of edges for testing\n",
    "    neg_sampling_ratio=1.0,      # For each positive edge, create one negative edge\n",
    "    edge_types=[('drug', 'causes', 'reaction')],\n",
    "    rev_edge_types=[('reaction', 'rev_causes', 'drug')], # Needed for undirected graphs\n",
    ")\n",
    "\n",
    "train_data, val_data, test_data = transform(data)\n",
    "\n",
    "print(\"\\n--- Data Splitting Complete ---\")\n",
    "print(\"Training Data Sample:\")\n",
    "print(train_data)\n",
    "print(\"\\nValidation Data Sample:\")\n",
    "print(val_data)\n",
    "print(\"\\nTest Data Sample:\")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f84af08-88f7-4d28-86ae-16bc7a27f0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GNN Model Architecture Defined and Instantiated ---\n",
      "Model(\n",
      "  (drug_lin): Linear(in_features=5, out_features=64, bias=True)\n",
      "  (reaction_lin): Linear(in_features=3471, out_features=64, bias=True)\n",
      "  (gnn): GraphModule(\n",
      "    (conv1): ModuleDict(\n",
      "      (drug__causes__reaction): SAGEConv(64, 64, aggr=mean)\n",
      "      (reaction__rev_causes__drug): SAGEConv(64, 64, aggr=mean)\n",
      "    )\n",
      "    (conv2): ModuleDict(\n",
      "      (drug__causes__reaction): SAGEConv(64, 64, aggr=mean)\n",
      "      (reaction__rev_causes__drug): SAGEConv(64, 64, aggr=mean)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (lin1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (lin2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Define the Graph Neural Network (GNN) Model ---\n",
    "from torch_geometric.nn import SAGEConv, to_hetero\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # We define our GNN layers\n",
    "        self.conv1 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # This defines how data flows through the layers\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        return x\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super().__init__()\n",
    "        # A simple linear layer to predict the link probability\n",
    "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, z_dict, edge_label_index):\n",
    "        # Get the embeddings for the drug and reaction nodes in our \"questions\"\n",
    "        row, col = edge_label_index\n",
    "        z = torch.cat([z_dict['drug'][row], z_dict['reaction'][col]], dim=-1)\n",
    "        \n",
    "        # Pass them through the linear layers\n",
    "        z = self.lin1(z).relu()\n",
    "        z = self.lin2(z)\n",
    "        return z.view(-1) # Flatten the output\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, data):\n",
    "        super().__init__()\n",
    "        # Define the encoders for each node type\n",
    "        self.drug_lin = torch.nn.Linear(data['drug'].x.shape[1], hidden_channels)\n",
    "        self.reaction_lin = torch.nn.Linear(data['reaction'].x.shape[1], hidden_channels)\n",
    "        \n",
    "        # Instantiate the GNN, making it heterogeneous\n",
    "        self.gnn = GNN(hidden_channels)\n",
    "        self.gnn = to_hetero(self.gnn, data.metadata(), aggr='sum')\n",
    "        \n",
    "        # Instantiate the decoder\n",
    "        self.decoder = Decoder(hidden_channels)\n",
    "\n",
    "    # Replace the old forward method with this one\n",
    "    def forward(self, data):\n",
    "        # Project the initial node features from the input data object\n",
    "        x_dict = {\n",
    "          'drug': self.drug_lin(data['drug'].x),\n",
    "          'reaction': self.reaction_lin(data['reaction'].x),\n",
    "        }\n",
    "        \n",
    "        # Get the final node embeddings from the GNN\n",
    "        z_dict = self.gnn(x_dict, data.edge_index_dict)\n",
    "        \n",
    "        # Use the decoder to get link predictions for the specific links we're interested in\n",
    "        return self.decoder(z_dict, data['drug', 'causes', 'reaction'].edge_label_index)\n",
    "\n",
    "# --- Instantiate the model ---\n",
    "model = Model(hidden_channels=64, data=data) # 64 is a common size for the hidden layer\n",
    "\n",
    "print(\"--- GNN Model Architecture Defined and Instantiated ---\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ad07c7-6fd7-4338-b641-b07b3a103a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "--- Starting Model Training ---\n",
      "Epoch: 010, Loss: 0.7113, Train AUC: 0.5087, Val AUC: 0.5060\n",
      "Epoch: 020, Loss: 0.6918, Train AUC: 0.5828, Val AUC: 0.5736\n",
      "Epoch: 030, Loss: 0.6863, Train AUC: 0.5920, Val AUC: 0.5852\n",
      "Epoch: 040, Loss: 0.6691, Train AUC: 0.6284, Val AUC: 0.6211\n",
      "Epoch: 050, Loss: 0.7432, Train AUC: 0.5567, Val AUC: 0.5568\n",
      "Epoch: 060, Loss: 0.6734, Train AUC: 0.6386, Val AUC: 0.6356\n",
      "Epoch: 070, Loss: 0.7011, Train AUC: 0.6262, Val AUC: 0.6194\n",
      "Epoch: 080, Loss: 0.6819, Train AUC: 0.6050, Val AUC: 0.5999\n",
      "Epoch: 090, Loss: 0.6747, Train AUC: 0.6265, Val AUC: 0.6227\n",
      "Epoch: 100, Loss: 0.6609, Train AUC: 0.6870, Val AUC: 0.6808\n",
      "Epoch: 110, Loss: 0.6977, Train AUC: 0.4306, Val AUC: 0.4317\n",
      "Epoch: 120, Loss: 0.6720, Train AUC: 0.6298, Val AUC: 0.6262\n",
      "Epoch: 130, Loss: 0.6041, Train AUC: 0.7623, Val AUC: 0.7573\n",
      "Epoch: 140, Loss: 0.5289, Train AUC: 0.8340, Val AUC: 0.8281\n",
      "Epoch: 150, Loss: 0.4400, Train AUC: 0.8898, Val AUC: 0.8850\n",
      "Epoch: 160, Loss: 0.7217, Train AUC: 0.8941, Val AUC: 0.8885\n",
      "Epoch: 170, Loss: 0.3753, Train AUC: 0.9180, Val AUC: 0.9130\n",
      "Epoch: 180, Loss: 0.3404, Train AUC: 0.9290, Val AUC: 0.9248\n",
      "Epoch: 190, Loss: 0.3319, Train AUC: 0.9324, Val AUC: 0.9282\n",
      "Epoch: 200, Loss: 0.3272, Train AUC: 0.9343, Val AUC: 0.9300\n",
      "\n",
      "--- Training Complete in 287.54 seconds ---\n",
      "\n",
      "Loading best model from: C:\\Users\\Sheetal\\PharmacoGraph-Agent\\data\\best_gnn_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sheetal\\AppData\\Local\\Temp\\ipykernel_6708\\2533380614.py:87: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test AUC: 0.9275\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Train the GNN Model (FINAL, SELF-CONTAINED VERSION) ---\n",
    "\n",
    "# --- All necessary imports for this cell ---\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "import os\n",
    "\n",
    "# --- Setup for Training ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move all data splits to the selected device (e.g., CPU or GPU)\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "test_data = test_data.to(device)\n",
    "\n",
    "# Re-instantiate the model to ensure it's fresh, then move to device\n",
    "model = Model(hidden_channels=64, data=data).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# --- Training Function ---\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Pass the entire training data object to the model\n",
    "    pred = model(train_data)\n",
    "    \n",
    "    # Use the correct key to access the edge labels\n",
    "    target = train_data['drug', 'causes', 'reaction'].edge_label\n",
    "    loss = criterion(pred, target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "# --- Testing Function ---\n",
    "@torch.no_grad()\n",
    "def test(data_split):\n",
    "    model.eval()\n",
    "    \n",
    "    # Pass the entire data split object to the model\n",
    "    pred = model(data_split)\n",
    "    \n",
    "    # Use the correct key to access the edge labels\n",
    "    target = data_split['drug', 'causes', 'reaction'].edge_label.float()\n",
    "    \n",
    "    auc = roc_auc_score(target.cpu().numpy(), pred.sigmoid().cpu().numpy())\n",
    "    return auc\n",
    "\n",
    "# --- The Training Loop ---\n",
    "start_time = time.time()\n",
    "print(\"\\n--- Starting Model Training ---\")\n",
    "best_val_auc = 0\n",
    "best_model_path = os.path.join(DATA_DIR, 'best_gnn_model.pt')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        train_auc = test(train_data)\n",
    "        val_auc = test(val_data)\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train AUC: {train_auc:.4f}, Val AUC: {val_auc:.4f}')\n",
    "\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\n--- Early stopping at epoch {epoch}. ---\")\n",
    "            break\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n--- Training Complete in {end_time - start_time:.2f} seconds ---\")\n",
    "\n",
    "# --- Final Evaluation on the Test Set ---\n",
    "print(f\"\\nLoading best model from: {best_model_path}\")\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "test_auc = test(test_data)\n",
    "print(f'\\nFinal Test AUC: {test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc403cf-59e8-475c-bade-7ffec085bafd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
